{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sdv.tabular import GaussianCopula\n",
    "from sdv.tabular import CTGAN\n",
    "from sdv.tabular import CopulaGAN\n",
    "from sdv.tabular import TVAE\n",
    "from sdv.metrics.tabular import CSTest, KSTest\n",
    "\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manhattan(object):\n",
    "    \"\"\"\n",
    "    Manhattan distance to the mean template vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "        self.mean = X.mean(axis=0)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        if X.ndim == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "        return np.abs((X - self.mean)).sum(axis=1)\n",
    "\n",
    "\n",
    "class ManhattanScaled(object):\n",
    "    \"\"\"\n",
    "    Manhattan scaled distance to the mean template vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "        self.mean = X.mean(axis=0)\n",
    "        self.absdev = np.abs(X - self.mean).mean(axis=0)\n",
    "        \n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        if X.ndim == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "        return np.abs((X - self.mean) / self.absdev).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eer(y_true, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n",
    "    eer = brentq(lambda x: 1.0 - x - interp1d(fpr, tpr)(x), 0.0, 1.0)\n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82, 15, 4, 95, 36, 32, 29, 18, 14, 87, 70, 12, 76, 55, 5, 28, 30, 65, 78, 72, 26, 92, 84, 90, 54, 58, 105, 1, 99, 21, 44, 20, 49, 13, 46, 110, 45, 34, 6, 94, 59, 69, 16, 11, 71, 38, 108, 81, 80, 112, 47, 74, 25, 91, 9]\n",
      "Synthetic training\n",
      "SLOW [105.0, 84.0, 21.0, 25.0, 30.0]\n",
      "MEDIUM [5.0, 11.0, 13.0, 20.0, 34.0, 38.0, 45.0, 47.0, 49.0, 58.0, 59.0, 70.0, 72.0, 74.0, 76.0, 78.0, 91.0]\n",
      "FAST [1.0, 4.0, 6.0, 9.0, 12.0, 14.0, 15.0, 16.0, 18.0, 26.0, 28.0, 29.0, 32.0, 36.0, 44.0, 46.0, 54.0, 55.0, 65.0, 69.0, 71.0, 80.0, 81.0, 82.0, 87.0, 90.0, 92.0, 94.0, 95.0, 99.0, 108.0, 110.0, 112.0]\n",
      "Authentication\n",
      "SLOW [89.0, 33.0, 68.0, 73.0, 77.0, 88.0, 60.0, 61.0]\n",
      "MEDIUM [2.0, 7.0, 10.0, 17.0, 22.0, 37.0, 39.0, 40.0, 50.0, 51.0, 52.0, 56.0, 57.0, 63.0, 66.0, 75.0, 79.0, 98.0, 100.0, 101.0]\n",
      "FAST [3.0, 8.0, 19.0, 23.0, 24.0, 27.0, 31.0, 35.0, 41.0, 42.0, 43.0, 48.0, 53.0, 62.0, 64.0, 67.0, 83.0, 85.0, 86.0, 97.0, 102.0, 103.0, 104.0, 106.0, 107.0, 109.0, 111.0]\n"
     ]
    }
   ],
   "source": [
    "# all data\n",
    "df = pd.read_csv(\"sapipin_no_outliers.csv\")\n",
    "users = set(df['user'])\n",
    "# exclude userid = 93, this user forms a single cluster\n",
    "# users.remove(93)\n",
    "\n",
    "# read results of clustering\n",
    "df_slow = pd.read_csv(\"sapipin_slow.csv\")\n",
    "users_slow = set(df_slow['user'])\n",
    "\n",
    "df_medium = pd.read_csv(\"sapipin_medium.csv\")\n",
    "users_medium = set(df_medium['user'])\n",
    "\n",
    "df_fast = pd.read_csv(\"sapipin_fast.csv\")\n",
    "users_fast = set(df_fast['user'])\n",
    "\n",
    "\n",
    "# select 55 users for synthetic training\n",
    "num_users_train = 55\n",
    "random.seed(42)\n",
    "\n",
    "users_train = []\n",
    "while len(users_train) < 55:\n",
    "    sample = rnd.sample(users, 1)\n",
    "    if users_train.count(sample[0])==0:\n",
    "        users_train.append(sample[0])\n",
    "print(users_train)\n",
    "\n",
    "users_train_slow = [x for x in users_slow if x in users_train]\n",
    "users_train_medium = [x for x in users_medium if x in users_train]\n",
    "users_train_fast = [x for x in users_fast if x in users_train]\n",
    "\n",
    "print(\"Synthetic training\")\n",
    "print('SLOW', users_train_slow)\n",
    "print('MEDIUM', users_train_medium)\n",
    "print('FAST', users_train_fast)\n",
    "\n",
    "users_auth_slow = [x for x in users_slow if x not in users_train]\n",
    "users_auth_medium = [x for x in users_medium if x not in users_train]\n",
    "users_auth_fast = [x for x in users_fast if x not in users_train]\n",
    "\n",
    "print(\"Authentication\")\n",
    "print('SLOW', users_auth_slow)\n",
    "print('MEDIUM', users_auth_medium)\n",
    "print('FAST', users_auth_fast)\n",
    "\n",
    "users_auth = [x for x in users if x not in users_train]\n",
    "\n",
    "df_train = df[ df['user'].isin(users_train)]\n",
    "df_auth = df[ df['user'].isin(users_auth)]\n",
    "\n",
    "df_auth_slow = df[ df['user'].isin(users_auth_slow)]\n",
    "df_auth_medium = df[ df['user'].isin(users_auth_medium)]\n",
    "df_auth_fast = df[ df['user'].isin(users_auth_fast)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GaussianCopula()\n",
    "# model = CTGAN()\n",
    "model = TVAE()\n",
    "model.fit(df_train)\n",
    "df_synth = model.sample()\n",
    "# df_synth.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL: #users 56\n",
      "\tAUC 10 mean  0.89 STD  0.11\n",
      "SLOW: #users  8\n",
      "\tAUC 10 mean  0.95 STD  0.05\n",
      "MEDIUM: #users 20\n",
      "\tAUC 10 mean  0.89 STD  0.13\n",
      "FAST: #users 27\n",
      "\tAUC 10 mean  0.87 STD  0.12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_list = [('ALL', df_auth), ('SLOW', df_auth_slow), ('MEDIUM', df_auth_medium), ('FAST', df_auth_fast)]\n",
    "\n",
    "\n",
    "for (name, df_eval) in df_list:\n",
    "\n",
    "    auc_list = list()\n",
    "\n",
    "    userids = set(df_eval['user'].to_list())\n",
    "\n",
    "    print(\"%s: #users %2d\" % (name, len(userids)) )\n",
    "\n",
    "    auc_mean_10 = []\n",
    "    auc_std_10 = []\n",
    "    for i in range (0,10):\n",
    "        for userid in userids:\n",
    "            user_train_data = df_eval.loc[df_eval.iloc[:, -1].isin([userid])]\n",
    "\n",
    "            # Select data for training\n",
    "            user_train_data = user_train_data.drop(user_train_data.columns[-1], axis=1)\n",
    "            user_array = user_train_data.values\n",
    "\n",
    "            train_samples = 10\n",
    "\n",
    "            num_samples = user_array.shape[0]\n",
    "            user_train = user_array[2:train_samples, :]\n",
    "            user_test = user_array[train_samples:num_samples, :]\n",
    "\n",
    "            # num, dim = user_test.shape\n",
    "            # synth_user_data = df_synth.loc[df_synth.iloc[:, -1].isin([userid])]\n",
    "            # synth_user_data = synth_user_data.drop(synth_user_data.columns[-1], axis=1)\n",
    "            # synth_user_array = synth_user_data.values\n",
    "            \n",
    "            num, dim = user_test.shape\n",
    "            synth_user_data = df_synth.sample(n = num)\n",
    "            synth_user_data = synth_user_data.drop(synth_user_data.columns[-1], axis=1)\n",
    "            synth_user_array = synth_user_data.values\n",
    "            \n",
    "            clf = ManhattanScaled()\n",
    "\n",
    "            clf.fit(user_train)\n",
    "\n",
    "\n",
    "            positive_scores = clf.decision_function(user_test)\n",
    "            negative_scores = clf.decision_function(synth_user_array)\n",
    "\n",
    "            # positive_scores, negative_scores = score_normalization(positive_scores, negative_scores)\n",
    "\n",
    "            # 0 - inlier; 1 - outlier\n",
    "            zeros = np.zeros(len(positive_scores))\n",
    "            ones = np.ones(len(negative_scores))\n",
    "            y = np.concatenate((zeros, ones), axis=0)\n",
    "            y_pred = np.concatenate((positive_scores, negative_scores), axis=0)\n",
    "\n",
    "            auc = roc_auc_score(y, y_pred)\n",
    "            eer = calculate_eer(y, y_pred)\n",
    "            auc_list.append(auc)\n",
    "        # print(\"\\tAUC mean %5.2f STD %5.2f\" % (np.mean(auc_list), np.std(auc_list)))\n",
    "        auc_mean_10.append( np.mean(auc_list) )\n",
    "        auc_std_10.append(np.std(auc_list))\n",
    "    print(\"\\tAUC 10 mean %5.2f STD %5.2f\" % (np.mean(auc_mean_10), np.mean(auc_std_10)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdmetrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb66329de20c883a0d5e1400520069feec464e0a4134a2c187145db362c1fb1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
